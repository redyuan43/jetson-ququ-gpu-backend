# Jetson QuQu GPU Backend

> åŸºäºJetson AGX Orinçš„GPUåŠ é€ŸQuQuè¯­éŸ³è¯†åˆ«åç«¯æœåŠ¡

[![GitHub](https://img.shields.io/badge/GitHub-redyuan43-blue?logo=github)](https://github.com/redyuan43/jetson-ququ-gpu-backend)
[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-nvidia--runtime-blue?logo=docker)](https://www.docker.com/)
[![CUDA](https://img.shields.io/badge/CUDA-12.6-green?logo=nvidia)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– é¡¹ç›®ç®€ä»‹

å°†[QuQu](https://github.com/yan5xu/ququ)é¡¹ç›®çš„FunASRè¯­éŸ³è¯†åˆ«åç«¯æ”¹é€ ä¸ºåŸºäºJetson AGX Orin GPUåŠ é€Ÿçš„æœåŠ¡ç«¯æ¶æ„ï¼Œæ”¯æŒå±€åŸŸç½‘å¤šå®¢æˆ·ç«¯è®¿é—®ã€‚é›†æˆOllama LLMè¿›è¡Œæ–‡æœ¬ä¼˜åŒ–å¤„ç†ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸš€ **GPUåŠ é€Ÿ**: FunASRæ¨¡å‹è¿è¡Œåœ¨CUDA GPUä¸Šï¼Œæ€§èƒ½æå‡3-5å€
- ğŸŒ **APIæœåŠ¡**: FastAPIæ„å»ºçš„RESTfulæ¥å£ï¼Œæ”¯æŒå¤šå®¢æˆ·ç«¯å¹¶å‘è®¿é—®
- ğŸ¤– **LLMé›†æˆ**: Ollamaæ–‡æœ¬ä¼˜åŒ–ï¼ˆåˆ é™¤å£å¤´ç¦…ã€æ ¼å¼åŒ–ã€æ·»åŠ æ ‡ç‚¹ï¼‰
- ğŸ³ **å®¹å™¨åŒ–**: Dockeréƒ¨ç½²ï¼Œå¼€ç®±å³ç”¨
- âš¡ **å¼€æœºè‡ªå¯**: é…ç½®å®Œæˆåè‡ªåŠ¨å¯åŠ¨ï¼Œæ— éœ€äººå·¥å¹²é¢„
- ğŸ’¾ **æ¨¡å‹ç¼“å­˜**: æŒä¹…åŒ–å­˜å‚¨ï¼Œé¿å…é‡å¤ä¸‹è½½

## ğŸ¯ æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | CPUæ¨¡å¼ | GPUæ¨¡å¼ | æå‡ |
|------|---------|---------|------|
| 1åˆ†é’ŸéŸ³é¢‘è¯†åˆ« | 5-10ç§’ | 1-2ç§’ | **3-5å€** |
| æ¨¡å‹åŠ è½½æ—¶é—´ | 60-90ç§’ | 17ç§’ | **4-5å€** |
| GPUæ˜¾å­˜å ç”¨ | 0GB | ~4GB | - |
| å¹¶å‘èƒ½åŠ› | ä½ | ä¸­é«˜ | - |

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æŠ€æœ¯æ ˆ

| ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| ç¡¬ä»¶å¹³å° | Jetson AGX Orin 64GB | NVIDIA Ampere GPU |
| æ“ä½œç³»ç»Ÿ | Ubuntu 20.04 | Linux 5.15.148-tegra |
| CUDA | 12.6 | GPUè®¡ç®—å¹³å° |
| PyTorch | 2.4.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| FunASR | 1.2.7 | é˜¿é‡Œè¾¾æ‘©é™¢è¯­éŸ³è¯†åˆ« |
| FastAPI | 0.115.0 | Webæ¡†æ¶ |
| Ollama | æœ¬åœ°éƒ¨ç½² | LLMæ¨ç†å¼•æ“ |
| Docker | nvidia-runtime | å®¹å™¨è¿è¡Œæ—¶ |

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Jetson AGX Orin Server               â”‚
â”‚         (192.168.100.38)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  å®¿ä¸»æœº (Host)                      â”‚    â”‚
â”‚  â”‚                                    â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚ Ollama   â”‚   â”‚ DeepResearch â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ :11434   â”‚   â”‚ æ¨¡å‹/å·¥å…·    â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Docker: ququ-backend              â”‚    â”‚
â”‚  â”‚                                     â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚ FastAPI  â”‚  â”‚ FunASR GPU   â”‚   â”‚    â”‚
â”‚  â”‚  â”‚ :8000    â”‚â”€â”€â”‚ ASR/VAD/PUNC â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚           â”‚
 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
 â”‚ QuQu   â”‚  â”‚ QuQu   â”‚
 â”‚Client 1â”‚  â”‚Client Nâ”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Jetson AGX Orinï¼ˆæˆ–å…¶ä»–æ”¯æŒCUDAçš„Jetsonè®¾å¤‡ï¼‰
- å·²å®‰è£…Docker with nvidia runtime
- å·²å®‰è£…Ollamaå¹¶è¿è¡Œï¼ˆå¯é€‰ï¼Œç”¨äºæ–‡æœ¬ä¼˜åŒ–ï¼‰

### ä¸€é”®å¯åŠ¨

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/redyuan43/jetson-ququ-gpu-backend.git
cd jetson-ququ-gpu-backend

# å¯åŠ¨æœåŠ¡
./start-ququ-backend.sh
```

ç­‰å¾…çº¦17ç§’æ¨¡å‹åŠ è½½å®Œæˆï¼ŒæœåŠ¡å³å¯ä½¿ç”¨ã€‚

### æ‰‹åŠ¨å¯åŠ¨

```bash
# å¯åŠ¨å®¹å™¨
docker-compose up -d ququ-backend

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f ququ-backend

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8000/api/health
```

## ğŸ“¡ APIä½¿ç”¨

### æœåŠ¡åœ°å€

- **æœ¬åœ°è®¿é—®**: http://localhost:8000
- **å±€åŸŸç½‘è®¿é—®**: http://192.168.100.38:8000
- **APIæ–‡æ¡£**: http://192.168.100.38:8000/docs

### APIç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
|------|------|------|
| `/api/health` | GET | å¥åº·æ£€æŸ¥ |
| `/api/status` | GET | æœåŠ¡çŠ¶æ€ |
| `/api/asr/transcribe` | POST | è¯­éŸ³è¯†åˆ« |
| `/api/llm/optimize` | POST | æ–‡æœ¬ä¼˜åŒ– |
| `/api/asr/transcribe-and-optimize` | POST | ä¸€ä½“åŒ–å¤„ç† |

### ä½¿ç”¨ç¤ºä¾‹

#### 1. è¯­éŸ³è¯†åˆ«

```bash
curl -X POST http://192.168.100.38:8000/api/asr/transcribe \
  -F "audio=@test.wav" \
  -F "use_vad=true" \
  -F "use_punc=true"
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "success": true,
  "text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘ä»¬å»å…¬å›­æ•£æ­¥å§ã€‚",
  "raw_text": "ä»Šå¤©å¤©æ°”å¾ˆå¥½æˆ‘ä»¬å»å…¬å›­æ•£æ­¥å§",
  "duration": 3.5,
  "language": "zh-CN"
}
```

#### 2. æ–‡æœ¬ä¼˜åŒ–

```bash
curl -X POST http://192.168.100.38:8000/api/llm/optimize \
  -H "Content-Type: application/json" \
  -d '{
    "text": "è¿™ä¸ªå—¯é‚£ä¸ªå°±æ˜¯è¯´æˆ‘ä»¬ä»Šå¤©è¦å¼€ä¼š",
    "mode": "optimize"
  }'
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "success": true,
  "original_text": "è¿™ä¸ªå—¯é‚£ä¸ªå°±æ˜¯è¯´æˆ‘ä»¬ä»Šå¤©è¦å¼€ä¼š",
  "optimized_text": "æˆ‘ä»¬ä»Šå¤©è¦å¼€ä¼šã€‚",
  "mode": "optimize",
  "model": "gpt-oss:20b"
}
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

åœ¨ `docker-compose.yml` ä¸­å¯é…ç½®ï¼š

```yaml
environment:
  - CUDA_VISIBLE_DEVICES=0          # GPUè®¾å¤‡ID
  - OLLAMA_BASE_URL=http://localhost:11434  # Ollamaåœ°å€
  - OLLAMA_MODEL=gpt-oss:20b        # LLMæ¨¡å‹åç§°
  - SERVER_PORT=8000                # APIç«¯å£
  - SERVER_WORKERS=1                # å·¥ä½œè¿›ç¨‹æ•°
```

### æ¨¡å‹ç¼“å­˜

æ¨¡å‹ç¼“å­˜æŒä¹…åŒ–åˆ°å®¿ä¸»æœºï¼Œé¿å…é‡å¤ä¸‹è½½ï¼š

```yaml
volumes:
  - /data/deepresearch/modelscope_cache:/root/.cache/modelscope
```

ç¼“å­˜å¤§å°çº¦2GBï¼ŒåŒ…å«ï¼š
- ASRæ¨¡å‹ï¼ˆParaformer-largeï¼‰: 840MB
- VADæ¨¡å‹ï¼ˆFSMN-VADï¼‰: 278MB
- PUNCæ¨¡å‹ï¼ˆCT-Transformerï¼‰: å°äº100MB

## ğŸ›ï¸ å¼€æœºè‡ªå¯

æœåŠ¡å·²é…ç½®ä¸ºå¼€æœºè‡ªå¯åŠ¨ï¼š

```bash
# æ£€æŸ¥è‡ªå¯é…ç½®
./check-autostart.sh
```

å¯åŠ¨æµç¨‹ï¼š
1. è®¾å¤‡å¼€æœº (~30ç§’)
2. DockeræœåŠ¡å¯åŠ¨ (~5ç§’)
3. å®¹å™¨è‡ªåŠ¨å¯åŠ¨ (~2ç§’)
4. FunASRæ¨¡å‹åŠ è½½ (~17ç§’)
5. **æ€»è®¡çº¦54ç§’åæœåŠ¡å°±ç»ª**

è¯¦è§ [AUTOSTART.md](./AUTOSTART.md)

## ğŸ“š æ–‡æ¡£

- [DEPLOYMENT_SUMMARY.md](./DEPLOYMENT_SUMMARY.md) - å®Œæ•´éƒ¨ç½²æ€»ç»“
- [AUTOSTART.md](./AUTOSTART.md) - å¼€æœºè‡ªå¯é…ç½®
- [CLAUDE.md](./CLAUDE.md) - Claude Codeé¡¹ç›®æŒ‡å—
- [GIT_REPORT.md](./GIT_REPORT.md) - Gitæäº¤æŠ¥å‘Š
- [ququ_backend/README.md](./ququ_backend/README.md) - åç«¯APIè¯¦ç»†æ–‡æ¡£

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**Q: GPUä¸å¯ç”¨ï¼Ÿ**
```bash
# æ£€æŸ¥nvidia-smi
nvidia-smi

# æ£€æŸ¥Docker GPUè¿è¡Œæ—¶
docker info | grep -i nvidia

# é‡å¯å®¹å™¨
docker-compose restart ququ-backend
```

**Q: Ollamaè¿æ¥å¤±è´¥ï¼Ÿ**
```bash
# æ£€æŸ¥OllamaæœåŠ¡
curl http://localhost:11434/v1/models

# ä»å®¹å™¨å†…æµ‹è¯•
docker exec ququ-backend curl http://localhost:11434/v1/models
```

**Q: æ¨¡å‹åŠ è½½ç¼“æ…¢ï¼Ÿ**
```bash
# æ£€æŸ¥æ¨¡å‹ç¼“å­˜
du -sh /data/deepresearch/modelscope_cache
# åº”è¯¥æ˜¾ç¤ºçº¦2.0GB

# å¦‚æœä¸ºç©ºï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½
```

æ›´å¤šé—®é¢˜è¯·å‚è€ƒ [DEPLOYMENT_SUMMARY.md](./DEPLOYMENT_SUMMARY.md)

## ğŸ› ï¸ å¼€å‘

### é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ ququ_backend/           # åç«¯æœåŠ¡ä»£ç 
â”‚   â”œâ”€â”€ server.py           # FastAPIä¸»æœåŠ¡
â”‚   â”œâ”€â”€ funasr_gpu.py      # GPUåŠ é€ŸFunASR
â”‚   â”œâ”€â”€ llm_client.py      # Ollamaå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ test_gpu.py        # GPUæµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ requirements.txt   # Pythonä¾èµ–
â”œâ”€â”€ docker-compose.yml      # Dockeré…ç½®
â”œâ”€â”€ start-ququ-backend.sh  # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ check-autostart.sh     # è‡ªå¯æ£€æŸ¥è„šæœ¬
â””â”€â”€ æ–‡æ¡£/                   # å®Œæ•´æ–‡æ¡£
```

### æµ‹è¯•GPUåŠ é€Ÿ

```bash
docker exec -it ququ-backend bash
cd /workspace/ququ_backend
python3 test_gpu.py
```

åº”è¯¥çœ‹åˆ°æ‰€æœ‰5ä¸ªæµ‹è¯•é€šè¿‡ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š

- [QuQu](https://github.com/yan5xu/ququ) - åŸå§‹QuQuå®¢æˆ·ç«¯é¡¹ç›®
- [DeepResearch](https://github.com/Alibaba-NLP/DeepResearch) - é˜¿é‡Œå·´å·´é€šä¹‰DeepResearch
- [FunASR](https://github.com/alibaba-damo-academy/FunASR) - è¾¾æ‘©é™¢è¯­éŸ³è¯†åˆ«æ¡†æ¶

## ğŸ™ è‡´è°¢

- QuQué¡¹ç›®ä½œè€… [@yan5xu](https://github.com/yan5xu)
- é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢ FunASRå›¢é˜Ÿ
- Ollamaå¼€æºç¤¾åŒº

## ğŸ“® è”ç³»æ–¹å¼

- GitHub: [@redyuan43](https://github.com/redyuan43)
- é¡¹ç›®ä¸»é¡µ: https://github.com/redyuan43/jetson-ququ-gpu-backend

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ªStarï¼**
