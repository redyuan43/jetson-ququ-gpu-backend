#!/bin/bash

echo "ğŸ§ª æµ‹è¯• Jetson DeepResearch ç¯å¢ƒ..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export LD_LIBRARY_PATH=/data/sensor-voice/sensor-voice/llama.cpp/build/bin:$LD_LIBRARY_PATH

MODEL_PATH="/data/sensor-voice/models/Alibaba-NLP_Tongyi-DeepResearch-30B-A3B-Q4_K_M.gguf"
LLAMA_BIN="/data/sensor-voice/sensor-voice/llama.cpp/build/bin"

echo "1ï¸âƒ£ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶..."
if [ -f "$MODEL_PATH" ]; then
    echo "âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: $(ls -lh $MODEL_PATH | awk '{print $5}')"
else
    echo "âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: $MODEL_PATH"
    exit 1
fi

echo "2ï¸âƒ£ æ£€æŸ¥ llama.cpp..."
if [ -f "$LLAMA_BIN/llama-cli" ]; then
    echo "âœ… llama-cli å¯ç”¨"
    $LLAMA_BIN/llama-cli --version
else
    echo "âŒ llama-cli ä¸å­˜åœ¨"
    exit 1
fi

echo "3ï¸âƒ£ æµ‹è¯•æ¨¡å‹åŠ è½½..."
timeout 10 $LLAMA_BIN/llama-cli \
  --model $MODEL_PATH \
  --ctx-size 512 \
  --n-gpu-layers 10 \
  --threads 4 \
  --predict 10 \
  --prompt "ä½ å¥½" \
  --no-display-prompt

if [ $? -eq 0 ]; then
    echo "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼"
else
    echo "âš ï¸  æ¨¡å‹åŠ è½½æµ‹è¯•ä¸­æ–­ï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„è¶…æ—¶ï¼‰"
fi

echo "4ï¸âƒ£ æµ‹è¯•å®Œæ•´æ¨ç†..."
echo "è¾“å…¥æµ‹è¯•é—®é¢˜: è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
$LLAMA_BIN/llama-cli \
  --model $MODEL_PATH \
  --ctx-size 1024 \
  --n-gpu-layers 35 \
  --threads 8 \
  --predict 50 \
  --temp 0.7 \
  --prompt "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½" \
  --no-display-prompt

echo "5ï¸âƒ£ æµ‹è¯•æœåŠ¡å™¨æ¨¡å¼..."
echo "å¯åŠ¨ llama-serverï¼ˆæŒ‰ Ctrl+C åœæ­¢ï¼‰..."
echo "å‘½ä»¤: $LLAMA_BIN/llama-server --model $MODEL_PATH --ctx-size 8192 --n-gpu-layers 35 --port 8080"

echo "âœ… ç¯å¢ƒæµ‹è¯•å®Œæˆï¼"
echo ""
echo "ğŸš€ ä¸‹ä¸€æ­¥:"
echo "   1. å¯åŠ¨æœåŠ¡å™¨: $LLAMA_BIN/llama-server --model $MODEL_PATH --ctx-size 8192 --n-gpu-layers 35 --port 8080"
echo "   2. æµ‹è¯• API: curl http://localhost:8080/v1/models"
echo "   3. è¿è¡Œ DeepResearch: cd /data/sensor-voice/DeepResearch && python inference/run_multi_react.py"