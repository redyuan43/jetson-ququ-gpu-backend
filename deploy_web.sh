#!/bin/bash

# DeepResearch Webç•Œé¢éƒ¨ç½²è„šæœ¬
# ç”¨äºè¿œç¨‹è®¿é—®Web GUI

echo "ğŸŒ éƒ¨ç½²DeepResearch Webç•Œé¢..."

# åœæ­¢ç°æœ‰å®¹å™¨
echo "ğŸ›‘ åœæ­¢ç°æœ‰å®¹å™¨..."
docker-compose down 2>/dev/null || true

# å¯åŠ¨æ¨¡å‹æœåŠ¡å™¨
echo "ğŸš€ å¯åŠ¨æ¨¡å‹æœåŠ¡å™¨..."
docker run -d --name deepresearch-web \
  --runtime nvidia \
  --ipc host \
  --privileged \
  --network host \
  -v /data/deepresearch:/workspace \
  -v /data/sensor-voice/models:/workspace/models \
  -v /data/sensor-voice/sensor-voice/llama.cpp:/workspace/llama.cpp \
  -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -e CUDA_VISIBLE_DEVICES=0 \
  -e TORCH_CUDA_ARCH_LIST=8.7 \
  -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128 \
  -e LLAMA_CUDA=1 \
  -e GGML_CUDA=1 \
  -e LD_LIBRARY_PATH=/workspace/llama.cpp/build/bin:$LD_LIBRARY_PATH \
  jetson_minicpm_v:latest bash -c "
    # å¯åŠ¨æ¨¡å‹æœåŠ¡å™¨
    export LD_LIBRARY_PATH=/workspace/llama.cpp/build/bin:\$LD_LIBRARY_PATH &&
    /workspace/llama.cpp/build/bin/llama-server \
      --model /workspace/models/Alibaba-NLP_Tongyi-DeepResearch-30B-A3B-Q4_K_M.gguf \
      --ctx-size 8192 \
      --n-gpu-layers 48 \
      --port 8004 \
      --host 0.0.0.0 > /tmp/server.log 2>&1 &

    # ç­‰å¾…æ¨¡å‹æœåŠ¡å™¨å¯åŠ¨
    sleep 15

    # å¯åŠ¨Webç•Œé¢
    cd /workspace/DeepResearch/WebAgent/WebDancer
    export GOOGLE_SEARCH_KEY=''
    export JINA_API_KEY=''
    export DASHSCOPE_API_KEY=''

    python3 -m demos.assistant_qwq_chat \
      --server_name=0.0.0.0 \
      --server_port=7860 \
      --share=True
  "

echo "âœ… Webç•Œé¢éƒ¨ç½²å®Œæˆï¼"
echo "ğŸ“¡ è®¿é—®åœ°å€: http://YOUR_SERVER_IP:7860"
echo "ğŸ” æŸ¥çœ‹æ—¥å¿—: docker logs deepresearch-web"
echo "ğŸ›‘ åœæ­¢æœåŠ¡: docker stop deepresearch-web && docker rm deepresearch-web"