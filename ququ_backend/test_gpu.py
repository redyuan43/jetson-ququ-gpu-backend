#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUåŠ é€Ÿæµ‹è¯•è„šæœ¬
éªŒè¯FunASRåœ¨GPUæ¨¡å¼ä¸‹çš„å·¥ä½œçŠ¶æ€
"""

import sys
import time
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def test_pytorch_gpu():
    """æµ‹è¯•PyTorch GPUæ”¯æŒ"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: PyTorch GPUæ”¯æŒ")
    logger.info("=" * 60)

    try:
        import torch

        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

        if torch.cuda.is_available():
            logger.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            logger.info(f"å½“å‰GPU: {torch.cuda.current_device()}")
            logger.info(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
            logger.info(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
            return True
        else:
            logger.error("âŒ CUDAä¸å¯ç”¨ï¼")
            return False

    except Exception as e:
        logger.error(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_funasr_import():
    """æµ‹è¯•FunASRå¯¼å…¥"""
    logger.info("")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•2: FunASRå¯¼å…¥")
    logger.info("=" * 60)

    try:
        import funasr
        from funasr import AutoModel

        logger.info(f"âœ… FunASRç‰ˆæœ¬: {getattr(funasr, '__version__', 'unknown')}")
        logger.info("âœ… AutoModelå¯¼å…¥æˆåŠŸ")
        return True

    except Exception as e:
        logger.error(f"âŒ FunASRå¯¼å…¥å¤±è´¥: {str(e)}")
        return False


def test_funasr_gpu_loading():
    """æµ‹è¯•FunASR GPUæ¨¡å¼åŠ è½½"""
    logger.info("")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•3: FunASR GPUæ¨¡å¼åŠ è½½")
    logger.info("=" * 60)

    try:
        from funasr import AutoModel
        import torch

        logger.info("åŠ è½½ASRæ¨¡å‹åˆ°GPU...")
        start_time = time.time()

        model = AutoModel(
            model="damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            model_revision="v2.0.4",
            disable_update=True,
            device="cuda:0"
        )

        load_time = time.time() - start_time
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼è€—æ—¶: {load_time:.2f}ç§’")

        # æ£€æŸ¥æ¨¡å‹ç¡®å®åœ¨GPUä¸Š
        if hasattr(model, 'model'):
            device = next(model.model.parameters()).device
            logger.info(f"âœ… æ¨¡å‹è®¾å¤‡: {device}")

            if device.type == 'cuda':
                logger.info("âœ… ç¡®è®¤ï¼šæ¨¡å‹åœ¨GPUä¸Šè¿è¡Œ")
                return True
            else:
                logger.warning("âš ï¸ æ¨¡å‹ä¸åœ¨GPUä¸Šï¼")
                return False
        else:
            logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆæ— æ³•æ£€æµ‹è®¾å¤‡ï¼‰")
            return True

    except Exception as e:
        logger.error(f"âŒ FunASR GPUåŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´çš„FunASR GPUç®¡ç†å™¨"""
    logger.info("")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•4: FunASR GPUç®¡ç†å™¨")
    logger.info("=" * 60)

    try:
        from funasr_gpu import FunASRServer

        logger.info("åˆå§‹åŒ–FunASR GPUæœåŠ¡å™¨...")
        server = FunASRServer()

        logger.info("å¼€å§‹åˆå§‹åŒ–æ¨¡å‹...")
        start_time = time.time()

        result = server.initialize()

        init_time = time.time() - start_time

        if result["success"]:
            logger.info(f"âœ… åˆå§‹åŒ–æˆåŠŸï¼æ€»è€—æ—¶: {init_time:.2f}ç§’")
            logger.info(f"   æ¶ˆæ¯: {result.get('message')}")

            # è·å–æ€§èƒ½ç»Ÿè®¡
            stats = server.get_performance_stats()
            logger.info(f"   æ¨¡å‹çŠ¶æ€:")
            logger.info(f"     - ASR: {stats['models_loaded']['asr']}")
            logger.info(f"     - VAD: {stats['models_loaded']['vad']}")
            logger.info(f"     - PUNC: {stats['models_loaded']['punc']}")

            return True
        else:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {result.get('error')}")
            return False

    except Exception as e:
        logger.error(f"âŒ FunASR GPUç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def test_gpu_memory():
    """æµ‹è¯•GPUæ˜¾å­˜ä½¿ç”¨"""
    logger.info("")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•5: GPUæ˜¾å­˜ç›‘æ§")
    logger.info("=" * 60)

    try:
        import torch

        if not torch.cuda.is_available():
            logger.warning("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æ˜¾å­˜æµ‹è¯•")
            return True

        allocated = torch.cuda.memory_allocated(0) / 1024**3
        reserved = torch.cuda.memory_reserved(0) / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3

        logger.info(f"GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ:")
        logger.info(f"  - å·²åˆ†é…: {allocated:.2f} GB")
        logger.info(f"  - å·²é¢„ç•™: {reserved:.2f} GB")
        logger.info(f"  - æ€»å®¹é‡: {total:.2f} GB")
        logger.info(f"  - ä½¿ç”¨ç‡: {(allocated/total)*100:.1f}%")

        if allocated > 0:
            logger.info("âœ… GPUæ˜¾å­˜æœ‰åˆ†é…ï¼ˆæ¨¡å‹å·²åŠ è½½åˆ°GPUï¼‰")
        else:
            logger.warning("âš ï¸ GPUæ˜¾å­˜æœªåˆ†é…ï¼ˆæ¨¡å‹å¯èƒ½æœªåœ¨GPUä¸Šï¼‰")

        return True

    except Exception as e:
        logger.error(f"âŒ GPUæ˜¾å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("\n\n")
    logger.info("ğŸš€ å¼€å§‹GPUåŠ é€ŸFunASRæµ‹è¯•")
    logger.info("=" * 60)

    results = {}

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    results["PyTorch GPU"] = test_pytorch_gpu()
    results["FunASRå¯¼å…¥"] = test_funasr_import()
    results["FunASR GPUåŠ è½½"] = test_funasr_gpu_loading()
    results["FunASRç®¡ç†å™¨"] = test_full_pipeline()
    results["GPUæ˜¾å­˜"] = test_gpu_memory()

    # æ€»ç»“
    logger.info("")
    logger.info("=" * 60)
    logger.info("æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)

    passed = sum(1 for v in results.values() if v)
    total = len(results)

    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")

    logger.info("")
    logger.info(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPUåŠ é€ŸFunASRå·¥ä½œæ­£å¸¸")
        return 0
    else:
        logger.error(f"âš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
